{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from tqdm import tqdm\n",
    "from thefuzz import fuzz\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from datasets import Dataset, load_dataset\n",
    "from setfit import SetFitModel, Trainer, TrainingArguments, sample_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_item = pd.read_csv('ArticlesContainingItems.csv', encoding='cp1252')\n",
    "items = pd.read_csv('ISItemsandVariables.csv', encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = r'/home/muellerrol/saras_folder/thesis/isrecon.duckdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(r'/home/muellerrol/saras_folder/thesis/isrecon.duckdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papers table from duckdb (the database)\n",
    "papers = con.execute('SELECT * FROM papers').fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching papers and papers_item on title and articletitle\n",
    "papers_item_merged = papers_item.merge(papers, left_on='articletitle', right_on='title')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_106663/3294962847.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  is_papers_item['title_short'] = is_papers_item['articletitle'].str.lower().str.replace('[^a-z0-9]', '').str[:20]\n",
      "/tmp/ipykernel_106663/3294962847.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  is_papers_item.rename(columns={'articletitle': 'title', 'journalname': 'journal'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Processing papers to get items relevant to each article\n",
    "papers = con.execute('SELECT * FROM papers INNER JOIN authors USING (article_id) WHERE author_position = 1').fetchdf()\n",
    "is_papers_item = papers_item[papers_item['journalname'].isin(papers['journal'].unique())]\n",
    "is_papers_item['title_short'] = is_papers_item['articletitle'].str.lower().str.replace('[^a-z0-9]', '').str[:20]\n",
    "papers['title_short'] = papers['title'].str.lower().str.replace('[^a-z0-9]', '').str[:20]\n",
    "is_papers_item.rename(columns={'articletitle': 'title', 'journalname': 'journal'}, inplace=True)\n",
    "is_merged = is_papers_item.merge(papers, left_on=['year', 'journal', 'title_short'], right_on=['year', 'journal', 'title_short'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 216/858 [00:00<00:00, 2156.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 858/858 [00:01<00:00, 685.48it/s] \n"
     ]
    }
   ],
   "source": [
    "item_sources_columns = ['article_id', 'SourceId', 'ItemId', 'Definition']\n",
    "item_sources = []\n",
    "\n",
    "for i, row in tqdm(is_merged.iterrows(), total=len(is_merged)):\n",
    "    source_id = row['SourceId']\n",
    "    article_id = row['article_id']\n",
    "    items_in_source = items[items['SourceId'] == source_id]\n",
    "    for _, item in items_in_source.iterrows():\n",
    "        row = [article_id, source_id, item['ItemId'], item['Definition']] \n",
    "        item_sources.append(row)\n",
    "\n",
    "item_sources_df = pd.DataFrame(item_sources, columns=item_sources_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading sentences table from the database\n",
    "sentences = con.execute('SELECT * FROM sentences').fetchdf()\n",
    "sentences = sentences[sentences['article_id'].isin(item_sources_df['article_id'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the fuzzy match function\n",
    "def fuzzy_match(sentence, definition_list, threshold=85):\n",
    "    found = False\n",
    "    best_definition = None\n",
    "    best_ratio = 0\n",
    "    for definition in definition_list:\n",
    "        if len(sentence) + 2 >= len(definition):\n",
    "            ratio = fuzz.partial_ratio(sentence, definition)\n",
    "            if ratio >= threshold and ratio > best_ratio:\n",
    "                best_ratio = ratio\n",
    "                best_definition = definition\n",
    "                found = True\n",
    "    return found, best_definition, best_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matched_definitions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition_list = list(item_sources_df['Definition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/446 [00:00<03:12,  2.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 446/446 [03:01<00:00,  2.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get unique article IDs\n",
    "unique_article_ids = list(item_sources_df['article_id'].unique())\n",
    "\n",
    "# unique article IDs iteration\n",
    "for article_id in tqdm(unique_article_ids, total=len(unique_article_ids)):\n",
    "   \n",
    "    article_sentences = sentences[sentences['article_id'] == article_id]\n",
    "\n",
    "    definitions_in_article = item_sources_df[item_sources_df['article_id'] == article_id]\n",
    "    \n",
    "    # Filter out any NaN or non-strings\n",
    "    definition_list = list(definitions_in_article['Definition'].dropna().astype(str))\n",
    "\n",
    "    # Fuzzy matching\n",
    "    for index, article_sentence in article_sentences.iterrows():\n",
    "        sentence_original = article_sentence['sentence_original']\n",
    "        if isinstance(sentence_original, str): \n",
    "            matched, definition, ratio = fuzzy_match(sentence_original, definition_list)\n",
    "            \n",
    "            if matched:\n",
    "                row = article_sentence.copy()\n",
    "                row['matched_definition'] = definition\n",
    "                row['ratio'] = ratio\n",
    "                row['definition_id'] = definitions_in_article[definitions_in_article['Definition'] == definition].iloc[0]['ItemId']  # Get ItemId or other identifier\n",
    "                row['definition_sentence'] = True\n",
    "                all_matched_definitions.append(row.to_frame().T)\n",
    "            else:\n",
    "                \n",
    "                if random.random() < 0.1:\n",
    "                    row = article_sentence.copy()\n",
    "                    row['matched_definition'] = None\n",
    "                    row['ratio'] = None\n",
    "                    row['definition_id'] = None\n",
    "                    row['definition_sentence'] = False\n",
    "                    all_matched_definitions.append(row.to_frame().T)\n",
    "all_matched_definitions_df = pd.concat(all_matched_definitions, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matched_definitions_df.to_csv('/home/muellerrol/saras_folder/thesis/extracted_definitions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking and Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed. Updated dataset size: 31244\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicated rows\n",
    "data = data.drop_duplicates().reset_index(drop=True)\n",
    "print(\"Duplicates removed. Updated dataset size:\", len(data))\n",
    "\n",
    "# Duplicates check\n",
    "duplicates = data.duplicated()\n",
    "print(f\"Number of duplicate rows: {duplicates.sum()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
